#!/usr/bin/env python

import rosbag
import rospy
import numpy as np
from PIL import Image, ImageDraw
import cv2
import glob, os
import re
from scipy.spatial.transform import Rotation as R
from datetime import datetime
import pickle

#variables for conversion from depth array to image and global points
near_clip = .01
far_clip = 3.5
v_res = 640
u_res = 480
focal_length = 57 * 3.14/180
dists = np.empty((v_res*u_res*4))

s_phi = np.repeat(np.reshape(np.sin((v_res/2-np.arange(v_res))*focal_length/v_res),(1,v_res)),u_res,axis=0)
c_phi = np.repeat(np.reshape(np.cos((v_res/2-np.arange(v_res))*focal_length/v_res),(1,v_res)),u_res,axis=0)
#flipped sin and cos to account for -a phase shift term
c_theta = np.repeat(np.reshape(np.sin((u_res/2-np.arange(u_res))*focal_length/u_res),(u_res,1)),v_res,axis=1)
s_theta = np.repeat(np.reshape(np.cos((u_res/2-np.arange(u_res))*focal_length/u_res),(u_res,1)),v_res,axis=1)

#parses data to get images, tf, and accelerometer data
def parse_data(bagfile):
  bag = rosbag.Bag(bagfile)

  accel = np.empty((0,4))
  tf = np.empty((0,8))
  depth_t = []

  for topic, msg, t in bag.read_messages():
    if topic == "/camera/depth/points":
      depth = np.reshape(np.array(msg.data),(480,640))
      depth = np.ones((480,640)) - depth
      depth *= 255
      depth = depth.astype(np.uint8)
      depth = np.flip(depth, axis=0)
      im = Image.fromarray(depth)
      d = ImageDraw.Draw(im)
      depth_t.append(t.to_sec())
      im.save("depth_{}.png".format(round(depth_t[-1],2)),"PNG")
    elif topic == "/accelerationVec":
      accel = np.vstack((accel,np.array([msg.x, msg.y, msg.z, t.to_sec()])))
    elif topic == "/tf":
      if msg.transforms[0].child_frame_id == 'ackerman':
        t_x = msg.transforms[0].transform.translation.x
        t_y = msg.transforms[0].transform.translation.y
        t_z = msg.transforms[0].transform.translation.z
        r_w = msg.transforms[0].transform.rotation.w
        r_x = msg.transforms[0].transform.rotation.x
        r_y = msg.transforms[0].transform.rotation.y
        r_z = msg.transforms[0].transform.rotation.z
        tf = np.vstack((tf,np.array([t_x,t_y,t_z,r_w,r_x,r_y,r_z,t.to_sec()])))
  
  depth_t.sort()
  accel = accel[accel[:,-1].argsort()]
  tf = tf[tf[:,-1].argsort()]
  
  return depth_t, accel, tf

#correlates images with tf values, and x,y locations with accelerometer values
def correlate_msgs(depth_t, accel, tf):
  t = 1
  d_tf = {}
  a_tf = np.empty((0,10))
  for d in depth_t:
    while t < tf.shape[0]-1 and tf[t,-1] < d:
      t += 1
      
    if abs(tf[t,-1]-d) < abs(tf[t-1,-1]-d):
      d_tf[round(d,2)] = tf[t]
    else:
      d_tf[round(d,2)] = tf[t-1]
  t = 1
  for a in accel:
    while t < tf.shape[0]-1 and tf[t,-1] < a[-1]:
      t += 1
    if abs(tf[t,-1]-a[-1]) < abs(tf[t-1,-1]-a[-1]):
      a_tf = np.vstack((a_tf,np.append(tf[t,:-1],a[:-1])))
    else:
      a_tf = np.vstack((a_tf,np.append(tf[t-1,:-1],a[:-1])))
  
  return d_tf, a_tf
  
#returns index values for the terrain grids given an x,y,max size,grid unit size, and grid center
def index_values(x,y,t_size, g_size, center=(0,0)):
  cell_n = int(t_size//g_size)
  i = x/g_size+cell_n/2-center[0]/g_size
  j = y/g_size+cell_n/2-center[1]/g_size
  i = np.rint(i)
  i = i.astype(np.int)
  j = np.rint(j)
  j = j.astype(np.int)
  return i,j
  
# turns the tf values into a grid for ease of searching 
def tf_to_grid(a_tf, t_size, g_size, center=(0,0)):
  cell_n = int(t_size//g_size)
  
  tf_grid = {}
  tf_index = np.empty((0,2),dtype=np.int)
  i,j = index_values(a_tf[:,0],a_tf[:,1],t_size,g_size)
  
  for c in range(len(i)):
    x = i[c]
    y = j[c]
    if (x,y) not in tf_grid.keys():
      tf_grid[(x,y)] = []
      tf_grid[(x,y)].append(list(a_tf[c]))
    else:
      tf_grid[(x,y)].append(list(a_tf[c]))
      tf_index = np.vstack((tf_index,[x,y]))
  
  tf_index = np.unique(tf_index,axis=0)
  tf_index = list(map(tuple,tf_index))
  return tf_grid, tf_index

#correlates image pixels with global points
def global_points(depth_filename, tf):
  global near_clip
  global far_clip
  global s_phi
  global c_phi
  global s_theta
  global c_theta
  t_x = tf[0]
  t_y = tf[1]
  t_z = tf[2]
  r_w = tf[3]
  r_x = tf[4]
  r_y = tf[5]
  r_z = tf[6]
  quat = np.array([r_x, r_y, r_z, r_w])
  trans = np.array([t_x, t_y, t_z])
  depth = cv2.imread(depth_filename,0)
  print(depth_filename)
  depth = depth.astype(np.float32)
  depth /= 255
  inf_dist = np.argwhere(depth==0)
  depth[inf_dist[:,0],inf_dist[:,1]] = -1000
  xyz = np.empty((u_res,v_res,3))
  distances = (far_clip-near_clip)*(np.ones(depth.shape)-depth) + near_clip
  xyz[:,:,2] = np.multiply(distances,c_theta)
  xyz[:,:,1] = np.multiply(np.multiply(distances,s_theta),c_phi)
  xyz[:,:,0] = np.multiply(np.multiply(distances,s_theta),s_phi)
  r = R.from_quat(quat)
  for i in range(xyz.shape[0]):
    xyz[i,:,:] = r.apply(xyz[i])
  xyz = xyz + trans
  return xyz
  
#gives points that have been explored in given image
def label_image_points(points, tf_index, tf_grid, tf, t_size, g_size, center=(0,0)):
  rot_a = {}
  max_ind = int(t_size//g_size)-1
  x_p,y_p = index_values(points[:,:,0],points[:,:,1],t_size,g_size,center)
  values = np.ones((points.shape[0],points.shape[1],2))*-1
  x = np.reshape(x_p,(-1))
  y = np.reshape(y_p,(-1))
  indices = zip(x,y)
  unique = list(set(tf_grid.keys()) & set(indices))
  both = set(indices).intersection(tf_grid.keys())
  true_index = [indices.index(a) for a in both]
  rotated_vecs = {}
  tf_cur = R.from_quat(tf[3:7])
  
  for loc in unique:
    vecs = np.array(tf_grid[loc])
    tf_far = R.from_quat(vecs[:,3:7])
    accels = vecs[:,-3:]
    rot = tf_cur * tf_far.inv()
    rotated_vecs[loc] = rot.apply(accels)
    
  for i in true_index:
    j_t = int(i%x_p.shape[1])
    i_t = int(np.floor(i/x_p.shape[1]))
    values[i_t,j_t] = [i_t,j_t]
    index = tuple((i_t,j_t))
    tup = tuple((x_p[i_t,j_t],y_p[i_t,j_t]))
    rot_a[index] = rotated_vecs[tup]
    
  return rot_a, values
  
  
def extract_data(bagFile):
  depth_t,accel,tf = parse_data(bagFile)
  d_tf, a_tf = correlate_msgs(depth_t,accel,tf)
  tf_grid, tf_index = tf_to_grid(a_tf, 10, .1)
  for time in depth_t:
    time = round(time,2)
    now = datetime.now()
    print(now.strftime("%H:%M:%S"))
    dist = global_points("depth_{}.png".format(time),d_tf[time])
    now = datetime.now()
    print(now.strftime("%H:%M:%S"))
    x,y = index_values(dist[:,:,0],dist[:,:,1],10,.1)
    found_dict, value_array = label_image_points(dist,tf_index,tf_grid,d_tf[time],10,.1)
    now = datetime.now()
    print(now.strftime("%H:%M:%S"))
    print(1)
    f = open("{}.pkl".format(time),"wb")
    pickle.dump(found_dict,f)
    f.close()
    np.save("indices_{}.npy".format(time),value_array)
  return depth_t


if __name__=='__main__':
  """
  dat = extract_data("_2020-06-26-16-27-48.bag")
  """
  names = []
  base_dir = os.getcwd()
  for d in os.listdir('.'):
    if os.path.isdir(d):
      os.chdir(d)
      print(d)
      for sd in os.listdir('.'):
        os.chdir(sd)
        curr_dir = os.listdir('.')
        print(sd)
        for f in curr_dir:
          if f.endswith('.bag'):
            times = extract_data(f)
            dir_l = [d+'/'+sd+'/']*len(times)
            names.append(list(map(list,zip(dir_l,times))))
            os.rename(f,'../../../archived/' + d + '/' + sd + '/{}'.format(f))
        os.chdir('..')
      os.chdir('..')
  names = np.array(names)
  np.save("dirs_and_files.npy",names)
